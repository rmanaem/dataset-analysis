{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "immune-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc, size, max, abs\n",
    "\n",
    "# Initialize a spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-fields",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "- Data sampling \n",
    "- Data cleaning \n",
    "- Data preparation and formatting\n",
    "- Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-canberra",
   "metadata": {},
   "source": [
    "#### Imbalanced Sampling of Data\n",
    "Label the datasets, remove unncessary fields, sample and save the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "prospective-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data sets, remove unncessary fields, sample and save the samples\n",
    "\n",
    "# This imbalanced sample will favor the fake label with a ratio of 2 to 1\n",
    "fake = pd.read_csv(\"../data/Fake.csv\")\n",
    "fake['label'] = 'Fake'\n",
    "fake = fake.drop(columns=[\"date\", \"subject\"])\n",
    "fake = fake.sample(21000)\n",
    "true = pd.read_csv(\"../data/True.csv\")\n",
    "true['label'] = 'True'\n",
    "true = true.drop(columns=[\"date\", \"subject\"])\n",
    "true = true.sample(10000)\n",
    "\n",
    "# Uncomment and run the cell to save the sample\n",
    "# fake.to_csv(\"../data/Imbalanced_Sample1_Fake.csv\", index=False, header=None)\n",
    "# true.to_csv(\"../data/Imbalanced_Sample1_True.csv\", index=False, header=None)\n",
    "\n",
    "# This imbalanced sample favors the true label with ratio of 2 to 1\n",
    "fake = pd.read_csv(\"../data/Fake.csv\")\n",
    "fake['label'] = 'Fake'\n",
    "fake = fake.drop(columns=[\"date\", \"subject\"])\n",
    "fake = fake.sample(11000)\n",
    "true = pd.read_csv(\"../data/True.csv\")\n",
    "true['label'] = 'True'\n",
    "true = true.drop(columns=[\"date\", \"subject\"])\n",
    "true = true.sample(20000)\n",
    "\n",
    "# Uncomment and run the cell to save the sample\n",
    "# fake.to_csv(\"../data/Imbalanced_Sample2_Fake.csv\", index=False, header=None)\n",
    "# true.to_csv(\"../data/Imbalanced_Sample2_True.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-permit",
   "metadata": {},
   "source": [
    "#### Balanced Sampling of Data\n",
    "Label the datasets, remove unncessary fields, sample and save the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "vocal-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% balanced sample\n",
    "fake = pd.read_csv(\"../data/Fake.csv\")\n",
    "fake['label'] = 'Fake'\n",
    "fake = fake.drop(columns=[\"date\", \"subject\"])\n",
    "fake = fake.sample(2300)\n",
    "true = pd.read_csv(\"../data/True.csv\")\n",
    "true['label'] = 'True'\n",
    "true = true.drop(columns=[\"date\", \"subject\"])\n",
    "true = true.sample(2200)\n",
    "\n",
    "# Uncomment and run the cell to save the sample\n",
    "# fake.to_csv(\"../data/Balanced_Sample1_Fake.csv\", index=False, header=None)\n",
    "# true.to_csv(\"../data/Balanced_Sample1_True.csv\", index=False, header=None)\n",
    "\n",
    "# Largest(~ 40000) balanced sample\n",
    "fake = pd.read_csv(\"../data/Fake.csv\")\n",
    "fake['label'] = 'Fake'\n",
    "fake = fake.drop(columns=[\"date\", \"subject\"])\n",
    "fake = fake.sample(22000)\n",
    "true = pd.read_csv(\"../data/True.csv\")\n",
    "true['label'] = 'True'\n",
    "true = true.drop(columns=[\"date\", \"subject\"])\n",
    "true = true.sample(21000)\n",
    "\n",
    "# Uncomment and run the cell to save the sample\n",
    "# fake.to_csv(\"../data/Balanced_Sample2_Fake.csv\", index=False, header=None)\n",
    "# true.to_csv(\"../data/Balanced_Sample2_True.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-asian",
   "metadata": {},
   "source": [
    "#### Collecting Stop Words\n",
    "Stop words were extracted from nltk, python string module and the articles themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "close-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/stop_punc.txt', 'r') as file:\n",
    "    stop_punc = file.read()\n",
    "stop_punc = stop_punc.split(',')\n",
    "stop_punc = list(set(stop_punc))\n",
    "stop_punc.append(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-climb",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "structural-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_file = '../data/Balanced_Sample2_Fake.csv'\n",
    "true_file = '../data/Balanced_Sample2_True.csv'\n",
    "\n",
    "# Filtering datapoints with missing features\n",
    "fake_rdd = spark.read.csv(fake_file).rdd\n",
    "fake_rdd = fake_rdd.filter(lambda x: x[0] is not None and x[1] is not None).map(lambda x: (x[0] + ' ' + x[1], x[2])).filter(lambda x: x[1]=='Fake')\n",
    "num_fake = fake_rdd.count()\n",
    "true_rdd = spark.read.csv(true_file).rdd\n",
    "true_rdd = true_rdd.filter(lambda x: x[0] is not None and x[1] is not None).map(lambda x: (x[0] + ' ' + x[1], x[2])).filter(lambda x: x[1]=='True')\n",
    "num_true = true_rdd.count()\n",
    "\n",
    "# Tokenizing articles and removing stop words from the article\n",
    "tokenizer = Tokenizer(inputCol=\"article\", outputCol=\"words\")\n",
    "fake_rdd = fake_rdd.map(lambda x: Row(article=x[0], label=x[1]))\n",
    "fake_df = spark.createDataFrame(fake_rdd)\n",
    "fake_df = tokenizer.transform(fake_df)\n",
    "fake_rdd = fake_df.rdd.map(lambda x: (x[0], [i for i in x[2] if i not in stop_punc], x[1]))\n",
    "true_rdd = true_rdd.map(lambda x:Row(article=x[0], label=x[1]))\n",
    "true_df = spark.createDataFrame(true_rdd)\n",
    "true_df = tokenizer.transform(true_df)\n",
    "true_rdd = true_df.rdd.map(lambda x: (x[0], [i for i in x[2] if i not in stop_punc], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-annual",
   "metadata": {},
   "source": [
    "#### Feature Extraction with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "joined-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 10\n",
    "\n",
    "fake_rdd = fake_rdd.map(lambda x: (x[1], x[2])).map(lambda x: Row(words=x[0], label=x[1]))\n",
    "fake_df = spark.createDataFrame(fake_rdd)\n",
    "hashingTF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=num_features)\n",
    "fake_df = hashingTF.transform(fake_df)\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features')\n",
    "idfModel = idf.fit(fake_df)\n",
    "fake_df = idfModel.transform(fake_df)\n",
    "fake_rdd = fake_df.rdd.map(lambda x: (x[3], x[1])).map(lambda x: ([np.take(x[0], i) for i in range(np.size(x[0]))], x[1]))\n",
    "\n",
    "true_rdd = true_rdd.map(lambda x: (x[1], x[2])).map(lambda x: Row(words=x[0], label=x[1]))\n",
    "true_df = spark.createDataFrame(true_rdd)\n",
    "hashingTF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=num_features)\n",
    "true_df = hashingTF.transform(true_df)\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features')\n",
    "idfModel = idf.fit(true_df)\n",
    "true_df = idfModel.transform(true_df)\n",
    "true_rdd = true_df.rdd.map(lambda x: (x[3], x[1])).map(lambda x: ([np.take(x[0], i) for i in range(np.size(x[0]))], x[1]))\n",
    "\n",
    "fake = fake_rdd.collect()\n",
    "true = true_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-shelter",
   "metadata": {},
   "source": [
    "### Defining Training and Test Sets Using KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "republican-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "fake_data = []\n",
    "for train_index, test_index in kf.split(fake):\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in train_index:\n",
    "        train.append(fake[i])\n",
    "    for i in test_index:\n",
    "        test.append(fake[i])\n",
    "    fake_data.append((train, test))\n",
    "true_data = []\n",
    "for train_index, test_index in kf.split(true):\n",
    "    train = []\n",
    "    test = []\n",
    "    for i in train_index:\n",
    "        train.append(true[i])\n",
    "    for i in test_index:\n",
    "        test.append(true[i])\n",
    "    true_data.append((train, test))\n",
    "data = []\n",
    "for i in range(len(fake_data)):\n",
    "    true_data[i][0].extend(fake_data[i][0])\n",
    "    true_data[i][1].extend(fake_data[i][1])\n",
    "data = true_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-drove",
   "metadata": {},
   "source": [
    "### Classification Using KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "appointed-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of 41804 datapoints containing\n",
      "20896 fake datapoints\n",
      "20908 true datapoints\n",
      "Using 5NN classifier and 5fold cross validation resulted in average f1 score of 0.9932783433773587\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "accuracy = []\n",
    "predict = []\n",
    "f1 = []\n",
    "for i in range(len(data)):\n",
    "    knn.fit([j[0] for j in data[i][0]], [j[1] for j in data[i][0]])\n",
    "    accuracy.append(knn.score([j[0] for j in data[i][1]], [j[1] for j in data[i][1]]))\n",
    "    predict.append(knn.predict([j[0] for j in data[i][1]]))\n",
    "for i in range(len(predict)):\n",
    "    f1.append(f1_score([j[1] for j in data[i][1]], predict[i].tolist(), pos_label=\"True\"))\n",
    "average_f1 = sum(f1)/len(f1)\n",
    "\n",
    "# KNN Result\n",
    "print('Classification of', num_fake + num_true, 'datapoints containing')\n",
    "print(num_fake, 'fake datapoints')\n",
    "print(num_true, 'true datapoints')\n",
    "print('Using 5NN classifier and 5fold cross validation resulted in average f1 score of', average_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-vision",
   "metadata": {},
   "source": [
    "### Classification Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ultimate-stationery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of 41804 datapoints containing: \n",
      "20896 fake datapoints\n",
      "20908 true datapoints\n",
      "Using random forest classifier with 40 trees, max depth of 20 and 5fold cross validation resulted in average f1 score of 0.9998086925268777\n"
     ]
    }
   ],
   "source": [
    "num_trees = 40\n",
    "max_depth = 20\n",
    "rf = RandomForestClassifier(n_estimators=num_trees, max_depth=max_depth)\n",
    "accuracy = []\n",
    "predict = []\n",
    "f1 = []\n",
    "for i in range(len(data)):\n",
    "    rf.fit([j[0] for j in data[i][0]], [j[1] for j in data[i][0]])\n",
    "    accuracy.append(rf.score([j[0] for j in data[i][1]], [j[1] for j in data[i][1]]))\n",
    "    predict.append(rf.predict([j[0] for j in data[i][1]]))\n",
    "for i in range(len(predict)):\n",
    "    f1.append(f1_score([j[1] for j in data[i][1]], predict[i].tolist(), pos_label=\"True\"))\n",
    "average_f1 = sum(f1)/len(f1)\n",
    "\n",
    "# Result\n",
    "print('Classification of', num_fake + num_true, 'datapoints containing: ')\n",
    "print(num_fake, 'fake datapoints')\n",
    "print(num_true, 'true datapoints')\n",
    "print('Using random forest classifier with', num_trees, 'trees, max depth of', max_depth, 'and 5fold cross validation resulted in average f1 score of', average_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-greensboro",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
